# ğŸ“„ CV Optimization API

This API enables extraction, structuring, and intelligent optimization of resumes based on job postings. It's built on a modern FastAPI backend and leverages AI technologies like OCR, LangChain, HuggingFace, or Ollama.

![Current Welcome Page](assets/welcome_page.png)

---

## ğŸ”§ Architecture Overview

| Stage                                                       | Description                                                                               | Resources                                                                                                                                          |
| ----------------------------------------------------------- | ----------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| ğŸ§  **Backend (FastAPI)**                                    | Modern Python framework - fast, typed, and scalable                                       | ğŸ“š [FastAPI Documentation](https://fastapi.tiangolo.com/)                                                                                           |
| ğŸ“ **Content Extraction (Docling, RapidOCR)**               | Fast OCR optimized for semi-structured documents (resumes)                                | ğŸ“š [Docling GitHub](https://github.com/docling-ai/docling), [RapidOCR GitHub](https://github.com/RapidAI/RapidOCR)                                  |
| ğŸ“¦ **CV â†’ JSON Conversion (LLM via LangChain + HF/Ollama)** | Transformation of free text into structured, standardized JSON schema                     | ğŸ“š [LangChain Docs](https://docs.langchain.dev/), [HuggingFace Hub](https://huggingface.co/models)                                                  |
| ğŸ¯ **CV Optimization (LLM)**                                | Resume adjustment based on job postings to maximize relevance                             | ğŸ“š [McKinsey - AI in Recruiting](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/the-future-of-recruiting) |
| ğŸ” **Standardized JSON Output**                             | Facilitates frontend integration, rendering, and document generation                      | â€”                                                                                                                                                   |
| ğŸ–¥ï¸ **Frontend (Static then Next.js)**                      | Currently pure HTML/CSS/JS. Migration to Next.js (App Router) planned.                    | ğŸ“š [Next.js Documentation](https://nextjs.org/)                                                                                                     |

---

## ğŸš€ Why This Project Matters

* âœ… **Robust stack** with no exotic dependencies
* ğŸ’¼ **Tangible impact** on users' employability
* ğŸ”„ **Scalable**: Potential extensions to cover letters, scoring, portfolios...
* ğŸ¤– **Targeted AI use**: Smart alignment with job postings and intelligent structuring

---

## ğŸ”® Frontend Roadmap

| Phase    | Content                                                                 |
| -------- | ---------------------------------------------------------------------- |
| âœ… Current | Static frontend (HTML, CSS, JS) in `app/static/`                       |
| ğŸ”œ Future | Migration to **Next.js** with App Router (upload, preview, scoringâ€¦)   |

---

## ğŸ› ï¸ Recommendations

### 1. Strict JSON Schema (via Pydantic)

* `personal_info`: name, email, phone
* `experiences`, `skills`, `education`, `certifications`, `languages`

### 2. Recommended LLM Models

* **Hugging Face**: Mixtral, T5/T0, Mistral
* **Ollama**: Llama3, Mistral (local) for privacy and performance

### 3. Frontend

* Build these pages with **Next.js**:
  * Resume upload
  * Job posting selection
  * Optimized resume preview (Word/PDF export)

---

## âœ¨ Features

* ğŸ” OCR parsing of resumes (PDF)
* ğŸ§  Job posting-aligned optimization
* ğŸ“Š Clean JSON structuring for frontend consumption
* ğŸ“ˆ Future possibilities: scoring, PDF/Word export

---

## âš™ï¸ Installation

### Prerequisites

* Python â‰¥ 3.9
* [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
* [Ollama](https://ollama.ai/) (optional for local LLM)

### Installation

```bash
git clone https://github.com/yourusername/cv-optimization-api.git
cd cv-optimization-api

python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

Download an Ollama model:

```bash
ollama pull llama3
```

---

## ğŸ§ª Usage

### Launch the API

```bash
python app/main.py
```

* Swagger: [http://localhost:8000/docs](http://localhost:8000/docs)
* ReDoc: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Endpoints

#### 1. `POST /api/process/cv`

Upload a resume (PDF), returns structured JSON.

```bash
curl -X POST "http://localhost:8000/api/process/cv" \
  -H "accept: application/json" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@your_resume.pdf"
```

#### 2. `POST /api/result/optimize`

Send structured JSON + job posting â†’ returns optimized resume.

---

## ğŸ“ Project Structure

```
ğŸ“ app
â”œâ”€â”€ main.py
â”œâ”€â”€ api/
â”‚   â””â”€â”€ v1/
â”‚       â””â”€â”€ endpoints/
â”‚           â”œâ”€â”€ process.py
â”‚           â””â”€â”€ result.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cv_models.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ cv_parser.py
â”‚   â””â”€â”€ cv_optimizer.py
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ styles.css
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ script.js
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ temp_files/
â””â”€â”€ extracted_markdown/
```

---

## âš ï¸ Error Handling

* **400**: Invalid file
* **422**: Validation error
* **500**: Server error (stacktrace in dev)

---

## ğŸš€ Deployment

```bash
gunicorn -w 4 -k uvicorn.workers.UvicornWorker app.main:app
```

* Add: logging, auth, env management (`pydantic.BaseSettings`)

---